
# collecting tweets from Bloomberg Twitter Channel
data_colletor():
https://colab.research.google.com/drive/1CCoR8zAugr5DO8FboibOrl42SAE3OB7u

#about FinBERT
FinBERT is a pre-trained language model specifically designed for financial sentiment analysis. 
It is based on the popular BERT (Bidirectional Encoder Representations from Transformers) architecture and 
is fine-tuned on financial datasets to achieve state-of-the-art performance on financial sentiment analysis tasks.
FinBERT has become a popular tool for financial analysts, traders, and investors who need to analyze 
the sentiment of financial news and social media posts to make informed investment decisions. 
Its ability to accurately capture the nuances of financial language and sentiment has made it 
a valuable tool for sentiment analysis in the finance industry.



#install and feed the data to pretrained Financial 

1) Install the required libraries: 
install the TensorFlow library and the Hugging Face Transformers library, which provides access to FinBERT.

2) Load the FinBERT model: You can use the Hugging Face Transformers library to load the pre-trained FinBERT model.


#Tokenize financial texts generated from data_collector(0: 
Use the tokenizer provided by the Transformers library to tokenize your financial texts. 
This involves breaking the text into smaller units, such as words or subwords, 
and converting them into numerical representations that can be understood by the model.
Prepare input: Once you have tokenized your texts, you'll need to prepare them for input to the model. 
This usually involves padding the sequences to a fixed length and creating attention masks to indicate 
which tokens are real and which are padded.

Run inference: You can now use the loaded FinBERT model to run inference on your input. 
The output will be a probability score between 0 and 1 indicating the sentiment of the input text.

#display the analysis
